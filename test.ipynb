{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model.utils.transfroms import get_train_transform, get_valid_transform, get_test_transform\n",
    "from model.dataset import CustomDataset\n",
    "\n",
    "HOME = ''\n",
    "HOME_DIR = f'../Data/ChEMBL/OCR_RGB_0'\n",
    "DATAFRAME_LIST = dict(train=f'data/chembl_31_smiles_train.csv',\n",
    "                        val=f'data/chembl_31_smiles_val.csv',\n",
    "                        test=f'data/chembl_31_smiles_test.csv')\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "ocr_dataset = CustomDataset(\n",
    "        data_df=DATAFRAME_LIST['val'],\n",
    "        # mode='val',\n",
    "        mode='test',\n",
    "        # transforms=get_valid_transform(),\n",
    "        # transforms=get_train_transform(),\n",
    "        transforms=get_test_transform(),\n",
    "        dir_path=HOME_DIR,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, gt_shr, gt_shr_mask, gt_thr, gt_thr_mask = ocr_dataset[14]\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(24, 6))\n",
    "ax[0].imshow(image[0])\n",
    "ax[1].imshow(gt_shr)\n",
    "ax[2].imshow(gt_shr_mask)\n",
    "ax[3].imshow(gt_thr)\n",
    "ax[4].imshow(gt_thr_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from model.dbnet import DBNet\n",
    "from model.loss import DBLoss\n",
    "\n",
    "model = DBNet(\n",
    "        inner_channels=192,\n",
    "        out_channels=96,\n",
    "        head_in_channels=480,\n",
    "        # inner_channels=128,\n",
    "        # out_channels=64,\n",
    "        # head_in_channels=320,\n",
    "        test=True,\n",
    "    )\n",
    "\n",
    "# model.load_state_dict(torch.load('model_weights.v9.mbv3s.final.pth'), strict=False)\n",
    "# model.load_state_dict(torch.load('model_weights.v9_rgb.mbv3s.5n192h480.final.pth'))\n",
    "model.load_state_dict(torch.load('model_weights.v9_rgb.mbv3s.5n192h480.30.pth'))\n",
    "model.cpu()\n",
    "model.eval()\n",
    "\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image, gt_shr, gt_shr_mask, gt_thr, gt_thr_mask = ocr_dataset[idx]\n",
    "image = ocr_dataset[idx]\n",
    "# image = ocr_dataset[54]\n",
    "image = image[None,]\n",
    "\n",
    "x = model(image)\n",
    "print(idx)\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, figsize=(24, 10))\n",
    "ax[0, 0].imshow(image[0].permute([1, 2, 0]).detach().numpy())\n",
    "# ax[0, 1].imshow(x[0, 0].detach().numpy())\n",
    "# ax[0, 2].imshow(x[0, 1].detach().numpy())\n",
    "# ax[0, 3].imshow(x[0, 2].detach().numpy())\n",
    "ax[0, 1].imshow(x[0, 1].detach().numpy())\n",
    "ax[0, 2].imshow(x[0, 2].detach().numpy())\n",
    "ax[0, 3].imshow(x[0, 3].detach().numpy())\n",
    "ax[1, 0].imshow(x[0, 4].detach().numpy())\n",
    "ax[1, 1].imshow(x[0, 5].detach().numpy())\n",
    "ax[1, 2].imshow(x[0, 6].detach().numpy())\n",
    "ax[1, 3].imshow(x[0, 7].detach().numpy())\n",
    "# ax[1, 0].imshow(gt_shr.detach().numpy())\n",
    "# ax[1, 1].imshow(gt_shr.detach().numpy() == 5)\n",
    "# ax[1, 2].imshow(gt_shr.detach().numpy() == 6)\n",
    "# ax[1, 3].imshow(gt_shr.detach().numpy() == 7)\n",
    "\n",
    "idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.parser import get_mol_conn_info, get_mol\n",
    "from utils.emnist import PredictAtomChar\n",
    "\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "def save_image(img, pred, idx):\n",
    "    now = datetime.now()\n",
    "    cur_time_str = now.strftime(\"%d%m%Y_%H%M%S\")\n",
    "\n",
    "    img = np.array(img*255, dtype=np.uint8)\n",
    "    pil_image = Image.fromarray(img, mode=\"L\")\n",
    "    pil_image.save(f\"tmp_img/{cur_time_str}_{idx}_{pred}.png\")\n",
    "\n",
    "def rule_func(pred):\n",
    "    if pred in [\"0\", \"D\", \"Q\"]:\n",
    "        pred = \"O\"\n",
    "    elif pred in [\"n\"]:\n",
    "        pred = \"N\"\n",
    "    elif pred in [\"z\", \"Z\"]:\n",
    "        pred = \"2\"\n",
    "    elif pred in [\"a\"]:\n",
    "        pred = \"Cl\"\n",
    "    # elif pred in [\"E\", \"t\"]:\n",
    "    #     pred = \"F\"\n",
    "    elif pred in [\"5\"]:\n",
    "        pred = \"S\"\n",
    "    return pred\n",
    "\n",
    "char_model = PredictAtomChar(return_img=True, rule_func=rule_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.parser import get_mol_conn_info, get_mol\n",
    "from utils.mmocr_infer import MMOCRInferCRNN\n",
    "\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "def save_image(img, pred, idx):\n",
    "    now = datetime.now()\n",
    "    cur_time_str = now.strftime(\"%d%m%Y_%H%M%S\")\n",
    "\n",
    "    # img = np.array(img*255, dtype=np.uint8)\n",
    "    # pil_image = Image.fromarray(img, mode=\"L\")\n",
    "    pil_image = Image.fromarray(img)\n",
    "    pil_image.save(f\"tmp_img/{cur_time_str}_{idx}_{pred}.png\")\n",
    "\n",
    "def rule_func(pred):\n",
    "    if pred in [\"0\", \"o\"]:\n",
    "        pred = \"O\"\n",
    "    elif pred in [\"n\"]:\n",
    "        pred = \"N\"\n",
    "    # elif pred in [\"z\", \"Z\"]:\n",
    "    #     pred = \"2\"\n",
    "    elif pred in [\"ci\"]:\n",
    "        pred = \"Cl\"\n",
    "    elif pred in [\"f\"]:\n",
    "        pred = \"F\"\n",
    "    elif pred in [\"s\"]:\n",
    "        pred = \"S\"\n",
    "    elif pred in [\"h\"]:\n",
    "        pred = \"H\"\n",
    "    return pred\n",
    "\n",
    "char_model = MMOCRInferCRNN(return_img=True, rule_func=rule_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del char_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_idx = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _func(idx):\n",
    "    result = re.findall('(?![cCnNoOhHF\\(\\/\\)\\=\\[\\]0-9)@#]).', ocr_dataset.df.canonical_smiles[_idx])\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "def denormalize(x, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "    # 3, H, W, B\n",
    "    ten = x.clone()\n",
    "    for t, m, s in zip(ten, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    # B, 3, H, W\n",
    "    ten = ten.permute(1, 2, 0)\n",
    "    return torch.clamp(ten, 0, 1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_img(_img):\n",
    "    # y = .2126 * _img[:, :, 2] + .7152 * _img[:, :, 1] + .0722 * _img[:, :, 0]\n",
    "    y = .33 * _img[:, :, 2] + .33 * _img[:, :, 1] + .33 * _img[:, :, 0]\n",
    "    # y = 0.33 * _img[:, 0, :, :] + 0.33 * _img[:, 1, :, :] + 0.33 * _img[:, 2, :, :]\n",
    "    # y = ((y > 0.8).to(dtype=torch.float32) - 0.5) / 0.22\n",
    "    y = y > 0.8\n",
    "    return y[:, :, None]\n",
    "\n",
    "plt.imshow(pre_img(denormalize(image[0])), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"----- {_idx} -----\")\n",
    "# while _func(_idx).__len__() == 0:\n",
    "#     _idx += 1\n",
    "# else:\n",
    "image = ocr_dataset[_idx]\n",
    "# image = ocr_dataset[253]\n",
    "# image, gt_shr, gt_shr_mask, gt_thr, gt_thr_mask = ocr_dataset[2]\n",
    "image = image[None,]\n",
    "\n",
    "neck_out = model.neck(image)\n",
    "out = model.head(neck_out)\n",
    "out = out.detach().cpu().numpy()\n",
    "\n",
    "contours, b_pair, pred_heavy_char_list, pred_char_list, pred_img_char_list, char_pos = get_mol_conn_info(out, image, char_model=char_model)\n",
    "\n",
    "_idx += 1\n",
    "\n",
    "try:\n",
    "    mol, smi = get_mol(contours, pred_heavy_char_list, b_pair)\n",
    "    print(smi)\n",
    "except:\n",
    "    for idx, img in enumerate(pred_img_char_list):\n",
    "        save_image(img, pred_char_list[idx], idx)\n",
    "    print('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, img in enumerate(pred_img_char_list):\n",
    "    save_image(img[:, :, 0], pred_char_list[idx], idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "img = image[0].permute(1, 2, 0).detach().numpy().copy()\n",
    "_contours, _ = cv2.findContours(255*np.array(out[0][2] > 0.1, dtype=np.uint8), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "tmp_contours = []\n",
    "for _polygon in _contours:\n",
    "    if _polygon.shape.__len__() > 1:\n",
    "        rect = cv2.minAreaRect(_polygon)\n",
    "        (x, y), (w, h), ang = rect\n",
    "        print(w*h)\n",
    "        if w * h > 20:\n",
    "            tmp_contours.append(_polygon)\n",
    "ax.imshow(cv2.drawContours(img, tmp_contours, -1, (5), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 4, figsize=(24, 10))\n",
    "ax[0, 0].imshow(image[0, 0].detach().numpy())\n",
    "# ax[0, 1].imshow(x[0, 0].detach().numpy())\n",
    "# ax[0, 2].imshow(x[0, 3].detach().numpy())\n",
    "ax[0, 1].imshow(out[0, 1])\n",
    "ax[0, 2].imshow(out[0, 2])\n",
    "ax[0, 3].imshow(out[0, 3])\n",
    "ax[1, 0].imshow(out[0, 4])\n",
    "ax[1, 1].imshow(out[0, 5])\n",
    "ax[1, 2].imshow(out[0, 6])\n",
    "ax[1, 3].imshow(out[0, 7])\n",
    "\n",
    "idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "IPythonConsole.drawOptions.addAtomIndices = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_pair[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_pair[3][19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "# for i in contours[1]: plt.scatter(i[0], i[1], s=4200, c='none', edgecolors='k', alpha=0.2)\n",
    "ax.imshow(image[0, :].detach().permute(1, 2, 0).numpy(), alpha=0.5, cmap='gray')\n",
    "\n",
    "# k = 0\n",
    "# for i in contours[1]: ax.scatter(i[0], i[1], s=10, c='k', alpha=0.5)\n",
    "# for i in contours[1]: ax.text(i[0], i[1]-1, k, fontsize=7); k += 1\n",
    "# # k = 0\n",
    "# # for i in contours[2]: ax.scatter(i[0], i[1], s=4200, c='none', edgecolors='b', alpha=0.2)\n",
    "# for i in contours[2]: ax.scatter(i[0], i[1], s=10, c='b', alpha=0.5)\n",
    "# for i in contours[2]: ax.text(i[0]+2, i[1]-2, k, fontsize=7); k += 1\n",
    "\n",
    "if contours[3] is not None:\n",
    "    k = 0\n",
    "    for i in contours[3]: ax.scatter(i[0], i[1], c='gray', s=10, alpha=0.5)\n",
    "    for i in contours[3]: ax.text(i[0]+2, i[1]+2, k, c='gray', fontsize=7); k += 1\n",
    "if contours[4] is not None:\n",
    "    k = 0\n",
    "    for i in contours[4]: ax.scatter(i[0], i[1], c='r', s=10, alpha=0.5)\n",
    "    for i in contours[4]: ax.text(i[0]+2, i[1]+2, k, c='r', fontsize=7); k += 1\n",
    "if contours[5] is not None:\n",
    "    k = 0\n",
    "    for i in contours[5]: ax.scatter(i[0], i[1], c='g', s=10, alpha=0.5)\n",
    "    for i in contours[5]: ax.text(i[0]+2, i[1]+2, k, c='g', fontsize=7); k += 1\n",
    "if contours[6] is not None:\n",
    "    k = 0\n",
    "    for i in contours[6]: ax.scatter(i[0], i[1], c='b', s=10, alpha=0.5)\n",
    "    for i in contours[6]: ax.text(i[0]+2, i[1]+2, k, c='b', fontsize=7); k += 1\n",
    "if contours[7] is not None:\n",
    "    k = 0\n",
    "    for i in contours[7]: ax.scatter(i[0], i[1], c='navy', s=10, alpha=0.5)\n",
    "    for i in contours[7]: ax.text(i[0]+2, i[1]+2, k, c='navy', fontsize=7); k += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('rdkit310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "245b9d6615daa1a3827d07c8eb27e2623b2ed10fac89f2a0a36a803424ad4263"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
