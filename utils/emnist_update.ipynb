{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doodleduck/miniconda3/envs/rdkit310/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.cuda.amp.grad_scaler import GradScaler\n",
    "from torch.cuda.amp.autocast_mode import autocast\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from emnist import NeuralNetwork, eminst_class\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "model = NeuralNetwork()\n",
    "# model.load_state_dict(torch.load(\"model_weights.emnist.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dir_path: str = '../tmp_img/'):\n",
    "        super().__init__()\n",
    "        self.image_list = []\n",
    "        self.label_list = []\n",
    "        for _dir in Path(dir_path).iterdir():\n",
    "            for _img in Path(_dir).iterdir():\n",
    "                self.image_list.append(_img)\n",
    "                self.label_list.append(eminst_class.index(_dir.stem))\n",
    "        self.transforms = A.Compose(\n",
    "            [\n",
    "                A.Resize(16, 16),\n",
    "                A.ChannelShuffle(),\n",
    "                A.Blur(blur_limit=(2, 2), always_apply=True),\n",
    "                A.ShiftScaleRotate(\n",
    "                    scale_limit=(-0.1, 0.1), rotate_limit=0, shift_limit=0, p=0.5\n",
    "                ),\n",
    "                # A.RandomBrightnessContrast(p=0.4),\n",
    "                A.Normalize(mean=(0.5), std=(0.22), max_pixel_value=1),\n",
    "                # A.Normalize(),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def load_image(self, img_path):\n",
    "        with Image.open(img_path) as pikybow_image:\n",
    "            image = np.array(pikybow_image, dtype=np.uint8)\n",
    "            # image = image.astype(np.float32)\n",
    "            # image /= 255\n",
    "        return image\n",
    "\n",
    "    def __getitem__(\n",
    "        self,\n",
    "        index: int,\n",
    "    ):\n",
    "        image = self.load_image(self.image_list[index])\n",
    "        label = self.label_list[index]\n",
    "        transformed = self.transforms(image=image)\n",
    "        image = transformed[\"image\"]\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def get_train_transform(image):\n",
    "    image = np.array(image, dtype=np.uint8)\n",
    "    # image = np.array(image, dtype=np.int16)\n",
    "    # image -= 255\n",
    "    # image *= -1\n",
    "    # image = image.astype(np.uint8)[:, :, None].repeat(3, axis=2)\n",
    "    x = train_transform(image=image)[\"image\"]\n",
    "    # x = F.pad(x, (2, 2, 2, 2), value=2.2727)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_test_transform(image):\n",
    "    image = np.array(image, dtype=np.uint8)\n",
    "    # image = np.array(image, dtype=np.int16)\n",
    "    # image -= 255\n",
    "    # image *= -1\n",
    "    # image = image.astype(np.uint8)[:, :, None].repeat(3, axis=2)\n",
    "    x = test_transform(image=image)[\"image\"]\n",
    "    # x = F.pad(x, (2, 2, 2, 2), value=2.2727)\n",
    "    return x\n",
    "\n",
    "\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Blur(blur_limit=(3, 5), p=0.4),\n",
    "        A.Resize(14, 14),\n",
    "        # A.ChannelShuffle(),\n",
    "        A.HorizontalFlip(True),\n",
    "        A.Rotate((90, 90), always_apply=True),\n",
    "        A.RandomBrightnessContrast(p=0.4),\n",
    "        A.GaussNoise((0, 255), 0, p=0.4),\n",
    "        # A.CoarseDropout(4, 4, 4, 1, 1, 1, p=0.3),\n",
    "        A.InvertImg(always_apply=True),\n",
    "        A.Normalize(mean=(0.5), std=(0.22)),\n",
    "        # A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(14, 14),\n",
    "        A.HorizontalFlip(True),\n",
    "        A.Rotate((90, 90), always_apply=True),\n",
    "        A.InvertImg(always_apply=True),\n",
    "        A.Normalize(mean=(0.5), std=(0.22)),\n",
    "        # A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(\n",
    "        f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\"\n",
    "    )\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer, autocast_enabled):\n",
    "\n",
    "    if autocast_enabled:\n",
    "        scaler = GradScaler()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True), autocast(enabled=autocast_enabled):\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            if not autocast_enabled:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "training_data = datasets.EMNIST(\n",
    "    split=\"byclass\",\n",
    "    # split='letters',\n",
    "    root=\"../emnist_data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=get_train_transform,\n",
    ")\n",
    "\n",
    "test_data = datasets.EMNIST(\n",
    "    split=\"byclass\",\n",
    "    # split='letters',\n",
    "    root=\"../emnist_data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=get_test_transform,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    training_data, batch_size=1024, shuffle=True, num_workers=4\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_data, batch_size=1024, shuffle=True, num_workers=4\n",
    ")\n",
    "\n",
    "custom_training_data = CustomDataset()\n",
    "custom_train_dataloader = DataLoader(\n",
    "    custom_training_data, batch_size=10, shuffle=True, num_workers=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# i = 0\n",
    "print(eminst_class[training_data[i][1]])\n",
    "plt.imshow(training_data[i][0].permute(1, 2, 0).numpy(), cmap='gray')\n",
    "i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.604630  [    0/697932]\n",
      "loss: 3.355000  [102400/697932]\n",
      "loss: 2.320687  [204800/697932]\n",
      "loss: 1.827979  [307200/697932]\n",
      "loss: 1.538533  [409600/697932]\n",
      "loss: 1.331674  [512000/697932]\n",
      "loss: 1.148307  [614400/697932]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 1.005614 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.169323  [    0/697932]\n",
      "loss: 0.932814  [102400/697932]\n",
      "loss: 0.945437  [204800/697932]\n",
      "loss: 0.914555  [307200/697932]\n",
      "loss: 0.884248  [409600/697932]\n",
      "loss: 0.752508  [512000/697932]\n",
      "loss: 0.816701  [614400/697932]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.679526 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.786908  [    0/697932]\n",
      "loss: 0.699120  [102400/697932]\n",
      "loss: 0.653312  [204800/697932]\n",
      "loss: 0.690941  [307200/697932]\n",
      "loss: 0.664745  [409600/697932]\n",
      "loss: 0.646918  [512000/697932]\n",
      "loss: 0.681952  [614400/697932]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.592249 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.702887  [    0/697932]\n",
      "loss: 0.601562  [102400/697932]\n",
      "loss: 0.595430  [204800/697932]\n",
      "loss: 0.629447  [307200/697932]\n",
      "loss: 0.606170  [409600/697932]\n",
      "loss: 0.644992  [512000/697932]\n",
      "loss: 0.576094  [614400/697932]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.541542 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.564728  [    0/697932]\n",
      "loss: 0.556252  [102400/697932]\n",
      "loss: 0.545893  [204800/697932]\n",
      "loss: 0.575781  [307200/697932]\n",
      "loss: 0.536403  [409600/697932]\n",
      "loss: 0.543342  [512000/697932]\n",
      "loss: 0.569562  [614400/697932]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.518211 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.594495  [    0/697932]\n",
      "loss: 0.513622  [102400/697932]\n",
      "loss: 0.487376  [204800/697932]\n",
      "loss: 0.520800  [307200/697932]\n",
      "loss: 0.510623  [409600/697932]\n",
      "loss: 0.458526  [512000/697932]\n",
      "loss: 0.536375  [614400/697932]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.490879 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.520458  [    0/697932]\n",
      "loss: 0.513548  [102400/697932]\n",
      "loss: 0.557056  [204800/697932]\n",
      "loss: 0.505817  [307200/697932]\n",
      "loss: 0.500484  [409600/697932]\n",
      "loss: 0.504148  [512000/697932]\n",
      "loss: 0.516279  [614400/697932]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.472551 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.474064  [    0/697932]\n",
      "loss: 0.519864  [102400/697932]\n",
      "loss: 0.518288  [204800/697932]\n",
      "loss: 0.507155  [307200/697932]\n",
      "loss: 0.462593  [409600/697932]\n",
      "loss: 0.502004  [512000/697932]\n",
      "loss: 0.457602  [614400/697932]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.466836 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.490055  [    0/697932]\n",
      "loss: 0.508993  [102400/697932]\n",
      "loss: 0.473862  [204800/697932]\n",
      "loss: 0.520828  [307200/697932]\n",
      "loss: 0.558781  [409600/697932]\n",
      "loss: 0.524734  [512000/697932]\n",
      "loss: 0.581015  [614400/697932]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.463056 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.495396  [    0/697932]\n",
      "loss: 0.463865  [102400/697932]\n",
      "loss: 0.489604  [204800/697932]\n",
      "loss: 0.459242  [307200/697932]\n",
      "loss: 0.504306  [409600/697932]\n",
      "loss: 0.457626  [512000/697932]\n",
      "loss: 0.479589  [614400/697932]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.460510 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    # train(custom_train_dataloader, model, loss_fn, optimizer, True)\n",
    "    train(train_dataloader, model, loss_fn, optimizer, True)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "    # if t % 5 == 0:\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"model_weights.fix.pth\")\n",
    "torch.save(model.state_dict(), \"model_weights.emnist.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x, y = custom_training_data[_idx]\n",
    "x = _x.to(device)\n",
    "y_hat = model(x[None])\n",
    "print(eminst_class[y_hat.argmax()])\n",
    "plt.imshow(_x.permute(1, 2, 0).numpy())\n",
    "\n",
    "_idx += 3\n",
    "\n",
    "# y_hat = y_hat.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('rdkit310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "245b9d6615daa1a3827d07c8eb27e2623b2ed10fac89f2a0a36a803424ad4263"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
